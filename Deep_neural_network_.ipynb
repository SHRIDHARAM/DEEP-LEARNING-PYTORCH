{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep neural network .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "DEEP NEURAL NETWORK "
      ],
      "metadata": {
        "id": "Tip1JB5DAX5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WE CANT ALWAYS FIT OUR MODEL WITH LINEAR BOUNDARIES, FOR GIVEN DATA. \n",
        "We combine linear models to create non linear model. "
      ],
      "metadata": {
        "id": "QVb0_rsXA9z6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "activation functions actually make the model smooth on curves"
      ],
      "metadata": {
        "id": "DAn85w2qHpLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn import datasets"
      ],
      "metadata": {
        "id": "5v6mkSljA3yg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_pts = 500\n",
        "x, y = datasets.make_circles(n_samples= n_pts, random_state= 123, noise= 0.1, factor=0.2)\n",
        "print(x,y)\n",
        "x_data= torch.Tensor(x)\n",
        "y_data= torch.Tensor(y.reshape(500,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE2hyW8qP0rz",
        "outputId": "6427d043-d67b-4a60-d58e-8185974607ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6.98553633e-01 -3.78289607e-01]\n",
            " [-2.48422424e-01  1.91071221e-01]\n",
            " [-1.78759035e-01  2.53697475e-01]\n",
            " [-7.30467124e-03 -2.59266690e-01]\n",
            " [-1.59844140e-01  2.66915921e-01]\n",
            " [-8.01071690e-01 -1.08656135e-01]\n",
            " [ 1.00816914e+00  2.07309295e-01]\n",
            " [ 4.39780516e-02 -2.80236072e-01]\n",
            " [-8.34853704e-02 -1.38114367e-01]\n",
            " [-9.88928208e-01 -9.26102014e-02]\n",
            " [ 8.83638650e-02  1.96647051e-01]\n",
            " [ 2.22010570e-01  5.62848283e-02]\n",
            " [ 7.74176833e-01  8.22258534e-01]\n",
            " [ 6.42098042e-02  1.77475658e-01]\n",
            " [ 3.29904597e-01 -6.76348560e-02]\n",
            " [ 9.37162087e-01  2.05987221e-01]\n",
            " [-2.00792169e-01  5.35547075e-02]\n",
            " [ 5.32997317e-02 -2.82138380e-01]\n",
            " [-9.93783900e-02 -3.28183801e-01]\n",
            " [ 1.02684872e+00 -2.66939738e-01]\n",
            " [-8.69193490e-01  6.85448273e-01]\n",
            " [-6.70339467e-03  2.44518907e-01]\n",
            " [ 2.31538284e-02 -8.12416827e-01]\n",
            " [ 1.03822075e-01  1.19298417e-01]\n",
            " [-9.57389366e-01 -3.49206448e-01]\n",
            " [-7.98982279e-02  2.30581375e-01]\n",
            " [ 1.31496662e-01  4.30585961e-02]\n",
            " [ 3.68169092e-02  9.51356467e-01]\n",
            " [ 6.71357733e-01 -8.52005557e-01]\n",
            " [-5.92423995e-01 -9.06468126e-01]\n",
            " [-2.03368923e-01  1.79751566e-02]\n",
            " [-6.39843083e-01  1.01623139e+00]\n",
            " [ 1.51660391e-01  5.94450475e-02]\n",
            " [ 5.27858756e-01  6.93188232e-01]\n",
            " [ 4.79252004e-02  6.57038408e-02]\n",
            " [ 2.38228127e-02  3.65960131e-01]\n",
            " [-2.51639758e-01 -1.11085978e+00]\n",
            " [-1.59722439e-01  2.27662525e-01]\n",
            " [ 6.33957120e-01  8.05109457e-01]\n",
            " [-2.37411050e-01  1.49990918e-01]\n",
            " [-1.65688002e-02 -3.73661233e-02]\n",
            " [ 1.01648364e+00  2.44963513e-01]\n",
            " [ 1.77752937e-01 -9.74138227e-01]\n",
            " [ 2.65603693e-01 -1.15903425e-01]\n",
            " [ 2.35184982e-01  1.00340667e+00]\n",
            " [ 9.78814310e-02  1.72914494e-01]\n",
            " [ 9.67468497e-01  2.56254993e-01]\n",
            " [-8.86839308e-03 -1.09688449e+00]\n",
            " [ 6.92954011e-01  4.78986050e-01]\n",
            " [-5.05312936e-01  8.93231542e-01]\n",
            " [ 3.41167501e-02  2.40601111e-01]\n",
            " [-1.12643872e-01 -1.05994125e+00]\n",
            " [ 1.03599760e+00  4.37050446e-01]\n",
            " [-9.71896141e-01  2.51453631e-01]\n",
            " [-1.55737365e-02 -1.58308310e-01]\n",
            " [-1.65925674e-02 -1.75067405e-01]\n",
            " [ 5.72863381e-03  2.23124956e-01]\n",
            " [-4.35038380e-02 -1.79867981e-02]\n",
            " [ 1.38284086e-01  8.51370719e-01]\n",
            " [-9.85430381e-01 -7.73417607e-02]\n",
            " [ 7.71991270e-01 -3.87529307e-01]\n",
            " [ 1.49387776e-01 -5.18991328e-02]\n",
            " [-2.70729970e-01  9.83602879e-01]\n",
            " [-4.00015179e-02  2.47414148e-01]\n",
            " [-9.69925519e-02 -1.45832531e-01]\n",
            " [-7.21136859e-01 -6.17806278e-01]\n",
            " [-2.89497883e-01  7.27324154e-01]\n",
            " [-5.17814228e-01 -7.55271308e-01]\n",
            " [-6.25730470e-01 -9.39072776e-01]\n",
            " [-3.30765557e-02 -1.07443577e+00]\n",
            " [-4.13343428e-01 -7.53129685e-01]\n",
            " [ 7.35328804e-01  6.23359303e-01]\n",
            " [-9.38256312e-01  7.19285593e-01]\n",
            " [-1.63116850e-01 -1.91057029e-01]\n",
            " [ 6.78593450e-02  3.18721027e-01]\n",
            " [-8.83259615e-01  2.73176070e-01]\n",
            " [ 5.11336426e-01  9.74002788e-01]\n",
            " [-5.20378560e-01 -8.25602563e-01]\n",
            " [-2.37592741e-01  4.10904288e-02]\n",
            " [ 8.89802469e-01 -6.13392358e-01]\n",
            " [-3.23413730e-01 -3.84619815e-03]\n",
            " [-3.30175910e-02  4.65226243e-02]\n",
            " [-1.76481109e-01 -6.20656523e-02]\n",
            " [ 8.59385281e-01 -8.88993093e-02]\n",
            " [-1.08607584e-01  1.95421515e-01]\n",
            " [ 6.87639987e-02 -3.28855627e-02]\n",
            " [-8.19824527e-02  1.10257588e+00]\n",
            " [ 1.15648063e-01 -1.54230358e-02]\n",
            " [-2.24516011e-01  1.36584273e-01]\n",
            " [-9.01696660e-01 -1.71596005e-02]\n",
            " [-8.16953009e-01 -3.75868971e-01]\n",
            " [ 1.01481955e+00 -3.30066894e-01]\n",
            " [ 5.60092235e-01  1.01942929e+00]\n",
            " [ 1.61437921e-01 -8.98646058e-01]\n",
            " [ 5.16481410e-01  7.99341635e-01]\n",
            " [ 1.33791382e-01  8.51433234e-02]\n",
            " [-1.08137410e+00  4.15676528e-01]\n",
            " [ 9.60801657e-02  2.98282492e-02]\n",
            " [-4.27850323e-01  2.39325920e-01]\n",
            " [ 1.71392647e-01  3.23390600e-02]\n",
            " [ 3.91240709e-01 -8.55483856e-01]\n",
            " [ 2.86871002e-01 -2.47307112e-01]\n",
            " [ 7.37790609e-01 -4.82815600e-01]\n",
            " [-8.11467833e-01  6.58862570e-01]\n",
            " [ 1.06985211e-01  1.03405613e+00]\n",
            " [ 6.88685243e-02  1.96534463e-01]\n",
            " [-1.00159001e-01  1.36645203e-01]\n",
            " [-7.39848623e-02  1.40166448e-01]\n",
            " [-7.55513190e-01 -5.91588659e-01]\n",
            " [ 1.92646036e-01  3.22343490e-01]\n",
            " [ 2.45444537e-02  1.03812966e-01]\n",
            " [-6.72617027e-02 -1.95361833e-01]\n",
            " [ 1.44500288e-01  1.58225214e-01]\n",
            " [ 4.05092197e-01 -1.01785246e+00]\n",
            " [ 8.91149144e-01  5.68504207e-02]\n",
            " [-1.40699077e-01 -7.05740127e-02]\n",
            " [-8.07149247e-01 -5.22017771e-01]\n",
            " [-2.09716680e-01 -2.72595612e-01]\n",
            " [ 2.61233665e-02  1.46168977e-01]\n",
            " [-8.53856158e-01 -5.46503376e-01]\n",
            " [ 1.47939447e-01 -1.10929770e+00]\n",
            " [ 2.50701635e-01  1.41451930e-01]\n",
            " [ 9.22883687e-01  3.39964225e-01]\n",
            " [-9.48056471e-01  1.33592776e-01]\n",
            " [ 9.19620605e-01 -3.88833270e-01]\n",
            " [ 2.43962647e-01 -1.69700993e-01]\n",
            " [-1.95092844e-01  1.83406762e-02]\n",
            " [-1.73632089e-02  3.13899311e-02]\n",
            " [-1.27834346e-01 -6.09913432e-02]\n",
            " [-2.33049668e-01  1.55284110e-01]\n",
            " [-4.21118424e-01 -1.81906487e-02]\n",
            " [-2.08339884e-01  4.88774580e-02]\n",
            " [-7.35262188e-02 -1.98163382e-01]\n",
            " [-6.43424508e-02 -3.69366101e-01]\n",
            " [ 8.27342565e-01  6.34373498e-01]\n",
            " [ 1.10390428e+00 -1.07414057e-01]\n",
            " [ 9.70739456e-01  5.37949000e-01]\n",
            " [ 1.59531447e-01 -8.24087613e-02]\n",
            " [-7.45202744e-01 -8.00964052e-01]\n",
            " [ 8.96686702e-03 -8.55866588e-01]\n",
            " [-2.09877482e-01 -1.15550595e-01]\n",
            " [-3.78108447e-01  9.96960001e-01]\n",
            " [-6.47170467e-01 -7.77601780e-01]\n",
            " [ 4.33864344e-02 -1.57128628e-01]\n",
            " [-8.69404585e-01  1.97800335e-01]\n",
            " [-1.59933522e-01 -1.70802676e-01]\n",
            " [-4.63602512e-01  7.73399613e-01]\n",
            " [-2.75799680e-01 -1.25030347e-01]\n",
            " [ 2.70197927e-01 -8.46952682e-02]\n",
            " [ 5.21079561e-02 -8.33917930e-02]\n",
            " [ 5.72850486e-01 -9.96643406e-01]\n",
            " [ 3.19710062e-01  1.09870071e+00]\n",
            " [ 1.94860260e-02 -9.68141477e-01]\n",
            " [-8.81101575e-02  3.26778860e-01]\n",
            " [ 3.49691771e-01 -9.15456350e-01]\n",
            " [-7.74597516e-01 -8.42087481e-01]\n",
            " [ 2.66530130e-01 -2.23707759e-01]\n",
            " [-7.49857793e-01  4.24806646e-01]\n",
            " [ 1.25068864e-01  1.36809578e-01]\n",
            " [ 3.68787367e-02  2.13132875e-01]\n",
            " [ 3.71114555e-02 -2.29953827e-01]\n",
            " [-1.00920827e-01 -1.35795806e-01]\n",
            " [ 5.42433891e-01 -6.97934539e-01]\n",
            " [ 3.67548797e-01 -1.06580906e+00]\n",
            " [ 2.44323991e-01 -1.00970254e-01]\n",
            " [-1.04339350e-01 -8.71186250e-02]\n",
            " [ 9.28417746e-01  1.12252556e-01]\n",
            " [-8.47753756e-01 -4.30556040e-01]\n",
            " [-2.50858014e-01 -9.74498007e-01]\n",
            " [-2.04844936e-01 -2.40969940e-02]\n",
            " [ 3.03795587e-01 -9.90515315e-01]\n",
            " [ 1.84818297e-01  1.88627440e-01]\n",
            " [ 1.21872718e-01  3.46058152e-02]\n",
            " [-4.17246950e-01 -9.17211014e-01]\n",
            " [-1.60258087e-01 -2.90643161e-01]\n",
            " [-6.32720712e-02 -1.01213974e-01]\n",
            " [-1.89839739e-01  9.51583258e-02]\n",
            " [ 2.80029222e-01  6.20933377e-02]\n",
            " [ 6.83538660e-01 -4.85568235e-01]\n",
            " [ 1.91210618e-01 -2.38884160e-02]\n",
            " [-6.07575379e-01 -9.41583558e-01]\n",
            " [-5.65253244e-02 -9.07832980e-02]\n",
            " [ 2.50580006e-01  1.30020176e-04]\n",
            " [ 9.60192465e-01 -3.84858897e-01]\n",
            " [ 6.55816744e-01  8.00703278e-01]\n",
            " [-1.50594303e-01 -8.47891053e-02]\n",
            " [-1.05852208e-01 -9.88911066e-01]\n",
            " [ 4.03309131e-02 -3.45660282e-02]\n",
            " [ 8.86881756e-01  2.36540316e-01]\n",
            " [-4.32917045e-02 -1.37674229e-01]\n",
            " [ 1.14342769e-01  3.15068553e-01]\n",
            " [ 8.93850414e-01  8.56093965e-01]\n",
            " [-9.11568321e-01 -6.07775706e-01]\n",
            " [-7.03976829e-02  1.29558586e-02]\n",
            " [ 3.60228510e-01 -8.71496932e-01]\n",
            " [-8.54096946e-01 -5.57396904e-01]\n",
            " [ 2.26226894e-01  1.79288963e-01]\n",
            " [ 1.06894673e+00 -1.44014727e-01]\n",
            " [ 8.29651873e-02 -2.17643221e-01]\n",
            " [-1.93495224e-01 -1.31591969e-01]\n",
            " [-1.16368196e-01  2.37731073e-01]\n",
            " [ 2.17796350e-01 -1.15365269e-01]\n",
            " [-6.06006501e-01  8.81085208e-01]\n",
            " [-8.79052518e-01  4.71944516e-01]\n",
            " [-2.98845015e-01 -2.94629071e-02]\n",
            " [ 9.44791015e-01 -6.28722863e-01]\n",
            " [ 6.78503194e-01  8.96850071e-01]\n",
            " [ 8.91981156e-01  3.64729998e-01]\n",
            " [ 9.07279299e-01  7.04104011e-01]\n",
            " [-4.04882841e-01  1.00236175e+00]\n",
            " [ 2.19224701e-01 -2.41420372e-01]\n",
            " [ 7.25728010e-01 -5.59935364e-01]\n",
            " [-3.01076144e-01 -1.19114081e-01]\n",
            " [ 6.37864146e-02 -1.73090400e-01]\n",
            " [-2.33004484e-01  1.00734767e+00]\n",
            " [-7.93573229e-01  6.40383621e-01]\n",
            " [ 2.26100059e-01 -2.44508101e-02]\n",
            " [ 2.73363278e-01 -3.26894080e-02]\n",
            " [ 7.14608653e-01  6.56218039e-01]\n",
            " [-1.03550053e+00  1.09511190e-01]\n",
            " [-2.45811458e-01  1.03326109e+00]\n",
            " [ 7.02606282e-01 -6.94979532e-01]\n",
            " [ 2.13408592e-01  1.32878965e+00]\n",
            " [ 8.11378890e-01  5.21342508e-01]\n",
            " [-5.98895511e-01 -8.23702277e-01]\n",
            " [-9.31531975e-01 -4.87833085e-01]\n",
            " [-1.00103854e-01 -2.08194641e-01]\n",
            " [-1.67155371e-01 -1.48365983e-01]\n",
            " [-5.19719682e-01 -8.72947187e-01]\n",
            " [ 6.37935645e-02 -5.21963893e-02]\n",
            " [-4.89431011e-01 -7.27595019e-01]\n",
            " [-2.22433117e-01 -7.52029030e-03]\n",
            " [-5.24259539e-01  7.15172810e-01]\n",
            " [-2.03994817e-02 -1.69047235e-01]\n",
            " [ 3.51623611e-01 -7.34175327e-01]\n",
            " [ 1.06193989e-02 -1.01030106e-01]\n",
            " [ 1.23002724e-01 -1.51243648e-01]\n",
            " [ 2.46417106e-02 -3.14763607e-01]\n",
            " [ 1.14025569e-02 -8.32798197e-02]\n",
            " [-1.01819940e-01 -1.95826410e-01]\n",
            " [-3.87139692e-01 -1.08595474e-01]\n",
            " [ 7.71309282e-01 -9.06562707e-03]\n",
            " [ 4.29177210e-01  7.44544202e-02]\n",
            " [ 6.98933873e-01 -8.82384223e-01]\n",
            " [ 9.37467905e-01 -2.68141079e-01]\n",
            " [ 7.69258406e-01 -3.55506485e-01]\n",
            " [ 2.34637786e-01 -1.98093662e-01]\n",
            " [ 9.79013320e-01 -2.54453960e-01]\n",
            " [ 1.57690735e-02 -1.97687621e-02]\n",
            " [-1.06489202e+00 -1.43215482e-01]\n",
            " [-1.40540687e-01 -1.92612401e-01]\n",
            " [-3.76683097e-01 -9.52729988e-01]\n",
            " [-1.03540602e+00 -3.59715766e-01]\n",
            " [ 7.83407917e-02  5.37520985e-02]\n",
            " [-7.79465567e-01 -7.12255804e-01]\n",
            " [ 2.45821521e-02  5.11484193e-02]\n",
            " [ 9.13876597e-01 -2.48697440e-01]\n",
            " [-4.37895972e-01  7.03968506e-01]\n",
            " [-1.07191971e+00  2.16533415e-01]\n",
            " [ 7.05538884e-01  6.73037277e-01]\n",
            " [ 7.70761470e-02 -2.49516324e-01]\n",
            " [-9.79850656e-02  1.14097102e-03]\n",
            " [-4.94662322e-03  2.12058665e-01]\n",
            " [-1.03861694e-01  1.16225060e+00]\n",
            " [-8.04865864e-01  3.99535042e-01]\n",
            " [ 8.37608542e-02 -1.62852199e-01]\n",
            " [ 3.28189548e-01  8.46762868e-01]\n",
            " [-5.41543562e-01  6.05526304e-01]\n",
            " [ 8.67997814e-01 -4.25740169e-01]\n",
            " [ 2.79270430e-02 -3.17120417e-01]\n",
            " [-8.56878561e-02 -8.84206506e-02]\n",
            " [-5.11705335e-02  2.87730884e-01]\n",
            " [ 6.80732096e-01 -5.76567471e-01]\n",
            " [-5.34835192e-01 -9.86830887e-01]\n",
            " [ 2.75075147e-01 -6.59278442e-02]\n",
            " [ 1.12942199e+00  2.64243067e-01]\n",
            " [-9.91525824e-01  2.03723127e-01]\n",
            " [-1.62369285e-01 -9.44327880e-02]\n",
            " [ 9.03939849e-01 -4.11392763e-02]\n",
            " [-1.00176402e+00 -3.15254710e-01]\n",
            " [-1.16674118e-02 -1.72351898e-01]\n",
            " [ 6.75055893e-03  1.98512452e-01]\n",
            " [ 1.69494948e-01 -1.74226531e-01]\n",
            " [ 1.55589730e-01 -1.86841266e-01]\n",
            " [-1.10492348e-01 -2.74190944e-01]\n",
            " [ 6.73979865e-01 -6.87489210e-01]\n",
            " [-2.39107159e-02  1.48948649e-01]\n",
            " [ 1.45966058e-01  3.35578482e-02]\n",
            " [-1.91719421e-01 -3.12477829e-01]\n",
            " [ 1.00854458e+00 -4.92118302e-01]\n",
            " [ 9.50624311e-01  2.32346304e-01]\n",
            " [ 8.75586872e-01  6.37639406e-01]\n",
            " [-7.40836819e-02  3.20728541e-01]\n",
            " [ 4.36087217e-01 -9.91554759e-01]\n",
            " [-1.08213425e+00  1.67996479e-01]\n",
            " [-1.53494334e-01  9.36452815e-01]\n",
            " [-5.20495175e-01 -6.86492694e-01]\n",
            " [ 1.15072388e-01 -1.08387963e+00]\n",
            " [-1.11191740e+00 -4.76430474e-01]\n",
            " [ 6.76421412e-02 -2.65777840e-01]\n",
            " [-7.61250864e-01  3.26797385e-01]\n",
            " [-1.00323195e+00  7.29658180e-01]\n",
            " [ 2.37090675e-02 -1.29359946e-01]\n",
            " [-1.24202057e-01 -2.49347304e-02]\n",
            " [-1.27546787e-01 -6.35470862e-02]\n",
            " [-1.04041508e+00  4.04797772e-01]\n",
            " [ 2.37457112e-01  1.26496982e-01]\n",
            " [ 1.97437357e-01  1.82488908e-01]\n",
            " [ 1.68999167e-01 -1.02519607e+00]\n",
            " [-1.02635932e+00  6.36336315e-02]\n",
            " [-3.77971656e-02 -2.91694860e-02]\n",
            " [-7.39593792e-01  7.67501624e-01]\n",
            " [-1.68331259e-01 -1.89212785e-01]\n",
            " [ 1.20903389e-01 -1.01784856e+00]\n",
            " [-6.75911382e-02  9.48615983e-01]\n",
            " [ 1.25942038e-01  2.11393133e-03]\n",
            " [-2.31180418e-01 -8.49632026e-01]\n",
            " [-9.23963817e-02 -2.18334872e-01]\n",
            " [ 5.21762337e-01  8.73401994e-01]\n",
            " [ 5.44735221e-02  3.26898381e-01]\n",
            " [-1.41719914e-02 -1.73993859e-01]\n",
            " [-1.13339265e+00 -7.66323042e-02]\n",
            " [ 2.11016330e-01  1.05225048e+00]\n",
            " [-7.80902429e-01  4.23439077e-01]\n",
            " [ 2.00696987e-01 -9.94435187e-01]\n",
            " [ 6.85971512e-01 -7.03462004e-01]\n",
            " [ 9.22088120e-01 -1.95754762e-01]\n",
            " [-4.91966869e-01 -1.67749635e-01]\n",
            " [ 8.56764398e-02 -1.60422963e-01]\n",
            " [ 8.84326006e-02 -1.16940855e-01]\n",
            " [-9.01430419e-02  1.11772674e+00]\n",
            " [-1.35647036e-01  9.47410111e-02]\n",
            " [-5.17675496e-01 -9.71668597e-01]\n",
            " [ 1.04443639e+00 -1.03113154e-02]\n",
            " [ 2.20762988e-01 -1.70017156e-01]\n",
            " [ 2.29572703e-01  6.15656755e-02]\n",
            " [ 1.10706729e-01  9.62410264e-02]\n",
            " [-3.85378633e-01 -1.43069249e-01]\n",
            " [ 1.61293097e-01 -8.07130918e-02]\n",
            " [-7.27274574e-01 -7.65748500e-01]\n",
            " [ 7.30447525e-02 -2.17843563e-01]\n",
            " [ 5.88627842e-01  9.86432202e-01]\n",
            " [-2.16246002e-02 -2.06581982e-01]\n",
            " [-1.88847789e-01 -1.89527664e-01]\n",
            " [-6.92650147e-02  1.04031866e+00]\n",
            " [ 4.56532306e-01 -8.98742594e-01]\n",
            " [ 1.12815897e+00  2.71808920e-01]\n",
            " [-3.83677325e-01  9.36750079e-01]\n",
            " [ 1.99946166e-01  1.05459036e+00]\n",
            " [ 1.57492390e-01 -1.77524284e-01]\n",
            " [-1.10711749e+00  1.64823512e-01]\n",
            " [-5.11678873e-02 -1.69342098e-01]\n",
            " [-7.78843507e-02  2.97262469e-01]\n",
            " [-1.05203623e+00 -5.84550565e-01]\n",
            " [-6.39869057e-01  8.65043298e-01]\n",
            " [ 2.05537328e-01 -2.64969453e-01]\n",
            " [ 7.45844329e-02  8.69492404e-02]\n",
            " [-1.30793477e-02  2.46970776e-01]\n",
            " [ 1.96467530e-02  9.31382528e-02]\n",
            " [ 2.46480036e-01 -1.66777638e-01]\n",
            " [-6.26673127e-02  8.20288221e-02]\n",
            " [-1.79794145e-02  8.70418993e-01]\n",
            " [-1.03435440e-01  1.76973507e-01]\n",
            " [-1.26123897e-01  2.29262588e-01]\n",
            " [ 2.23857604e-01  1.71999424e-02]\n",
            " [ 2.72820872e-01  1.07616496e-01]\n",
            " [ 8.20117962e-02  1.44809532e-01]\n",
            " [-4.97361054e-02  2.15546546e-01]\n",
            " [-5.69976282e-02 -2.84134961e-01]\n",
            " [ 4.15329186e-01  1.03347434e+00]\n",
            " [-4.62598978e-01  8.50900348e-01]\n",
            " [-9.93771529e-01  4.10016627e-01]\n",
            " [-7.74909948e-02  1.92743837e-01]\n",
            " [-9.43886346e-01 -2.36145701e-01]\n",
            " [ 8.99956572e-01  4.68578260e-01]\n",
            " [ 1.15934421e-01  1.85563854e-02]\n",
            " [ 2.03652047e-01 -9.19332592e-01]\n",
            " [ 9.57500717e-04 -2.55266396e-01]\n",
            " [-1.05024328e+00  1.56244481e-01]\n",
            " [-3.16936295e-01  1.27659928e-01]\n",
            " [-1.63727798e-01  1.73927027e-01]\n",
            " [-2.44662253e-01  7.03719043e-02]\n",
            " [-1.13850604e-02  2.03294822e-01]\n",
            " [ 8.17440403e-01  7.10450820e-01]\n",
            " [-7.32999577e-01 -5.77334730e-01]\n",
            " [ 2.92872940e-01 -1.03629792e+00]\n",
            " [-3.92253259e-01  7.41141987e-02]\n",
            " [ 1.07195385e+00  3.05480152e-01]\n",
            " [-5.56481074e-01  8.09931577e-01]\n",
            " [ 2.29375064e-01  1.61678485e-01]\n",
            " [ 2.25466643e-01  9.39853093e-02]\n",
            " [ 8.88416165e-01 -6.63522184e-01]\n",
            " [ 1.07687079e+00 -2.57223101e-01]\n",
            " [ 3.55613869e-01  1.18636691e-01]\n",
            " [-2.02179352e-01 -3.29011865e-01]\n",
            " [-1.72815755e-01 -1.74563005e-02]\n",
            " [-8.21031021e-01  6.70291512e-01]\n",
            " [-8.07526618e-01 -5.85070211e-01]\n",
            " [-9.04513317e-01 -3.16077904e-01]\n",
            " [-3.49142796e-01  1.01770500e+00]\n",
            " [ 1.05918664e+00  4.93926421e-02]\n",
            " [-3.72106538e-02  1.34735166e-01]\n",
            " [ 2.39337041e-01  1.21399645e+00]\n",
            " [ 3.27623091e-02  1.24040812e-03]\n",
            " [ 8.76446798e-01 -5.86964581e-01]\n",
            " [-1.38623609e-01  1.40983961e-01]\n",
            " [ 3.54607229e-01  9.90552610e-01]\n",
            " [ 9.35191644e-01  1.82695070e-01]\n",
            " [ 9.74732873e-01  4.65562722e-01]\n",
            " [ 2.00367082e-01  9.85858892e-02]\n",
            " [ 1.87528778e-01 -2.01862712e-01]\n",
            " [ 1.55038201e-01  2.15218184e-01]\n",
            " [ 8.69022439e-01  5.44428525e-01]\n",
            " [-7.53645315e-02 -1.22178655e+00]\n",
            " [-2.91710938e-01  8.42818380e-02]\n",
            " [-1.69937494e-01 -7.55348066e-01]\n",
            " [ 3.03895801e-01  9.16881301e-01]\n",
            " [-8.29373702e-01 -5.22330089e-02]\n",
            " [-2.15069125e-01  2.30603250e-02]\n",
            " [ 1.05597729e+00 -2.30252657e-01]\n",
            " [ 1.86474329e-01  9.41865073e-02]\n",
            " [ 1.44473433e-01  1.05101736e-01]\n",
            " [-2.16363926e-01 -1.70604671e-01]\n",
            " [ 2.68103278e-01  6.10425057e-03]\n",
            " [-7.77611141e-01 -6.92569483e-01]\n",
            " [-2.16780137e-01  7.39526703e-02]\n",
            " [ 1.09406811e-01 -1.38785496e-02]\n",
            " [-1.61085409e-01  1.04649147e+00]\n",
            " [-2.02127908e-01 -1.44675120e-01]\n",
            " [-6.40748132e-01 -6.36740294e-01]\n",
            " [ 1.06171678e-01 -1.73421380e-01]\n",
            " [ 1.67551458e-01 -3.50642017e-01]\n",
            " [ 3.35693713e-01  3.56314086e-01]\n",
            " [-8.16178249e-01 -4.22213354e-01]\n",
            " [ 2.76821121e-01 -9.74283031e-01]\n",
            " [ 2.58274757e-01  1.65592727e-01]\n",
            " [-1.95770036e-01 -6.86290589e-02]\n",
            " [ 4.31596119e-02  1.70548324e-01]\n",
            " [-9.70353809e-02 -1.80088983e-01]\n",
            " [-1.94904541e-01  2.11127748e-01]\n",
            " [ 1.42668409e-01  1.17248569e+00]\n",
            " [-2.09443328e-01  2.47274425e-01]\n",
            " [ 2.62455753e-01 -8.59051985e-02]\n",
            " [-2.87392912e-01 -1.91489748e-01]\n",
            " [-5.15174310e-01 -8.47290313e-01]\n",
            " [-3.48625362e-01  8.81897227e-01]\n",
            " [-1.77503041e-02  2.03937211e-01]\n",
            " [-1.69176779e-02 -2.49949884e-01]\n",
            " [-1.16960502e-01 -7.03904739e-02]\n",
            " [-1.05031095e+00  2.47983471e-01]\n",
            " [ 4.86128262e-01 -8.62010657e-01]\n",
            " [-2.84022135e-02  3.17505280e-02]\n",
            " [-2.67415676e-01  1.40459952e-01]\n",
            " [ 8.09204173e-03 -1.00625425e+00]\n",
            " [-7.88188743e-02  2.60115190e-01]\n",
            " [-1.65867724e-01 -5.20584368e-02]\n",
            " [-8.81623073e-01  4.65409202e-01]\n",
            " [-7.65765970e-02  8.70242992e-02]\n",
            " [-8.35303067e-01 -1.49797356e-01]\n",
            " [-3.46716314e-01 -1.07721046e+00]\n",
            " [ 7.87432212e-02 -2.59708139e-01]\n",
            " [ 2.19690108e-01 -1.55990310e-01]\n",
            " [-6.00562059e-01  8.43427575e-01]\n",
            " [ 2.92841842e-01  1.55886284e-02]\n",
            " [ 6.74713131e-01  7.07239729e-01]\n",
            " [-2.33192512e-01  1.45186279e-01]\n",
            " [ 1.21530709e+00  1.17672930e-01]\n",
            " [-4.00973653e-02 -1.96212152e-01]\n",
            " [ 2.96095156e-02  1.42989320e-01]\n",
            " [ 9.88037620e-02  1.80812836e-01]\n",
            " [-1.67723363e-01  1.11648710e+00]\n",
            " [ 3.21761251e-01 -9.66364289e-01]\n",
            " [ 1.06015873e-01 -1.53696692e-01]\n",
            " [-1.58031163e-01 -1.32117815e-01]\n",
            " [ 3.09085063e-01  1.06669487e-01]\n",
            " [-2.04844119e-01  1.60763541e-01]\n",
            " [-7.83454013e-02  1.81257982e-01]\n",
            " [-7.42411200e-04 -2.18383700e-01]\n",
            " [-9.23101916e-01  3.05319852e-01]\n",
            " [ 8.19097901e-01 -7.15819989e-01]\n",
            " [-1.30370035e-01 -2.69468536e-01]\n",
            " [ 6.37286375e-01  8.75101351e-01]\n",
            " [-1.43301315e-01  9.44116672e-01]\n",
            " [ 3.97072425e-01  7.65633605e-01]\n",
            " [-1.01761342e+00 -9.16862411e-03]\n",
            " [-8.40296123e-01  3.29722054e-01]\n",
            " [-7.02652140e-01  6.95788156e-01]\n",
            " [ 8.35917113e-01 -7.27461170e-01]\n",
            " [ 5.76183846e-01 -6.42799752e-01]\n",
            " [ 2.20179935e-01  1.03988488e+00]\n",
            " [-9.92065426e-01  1.16188458e-01]\n",
            " [-9.82625390e-01  3.01573904e-01]\n",
            " [-5.30935997e-01  9.23976060e-01]\n",
            " [ 9.20888959e-01  5.15771449e-01]\n",
            " [ 9.11451732e-01 -4.77269454e-01]\n",
            " [-6.45713806e-01  7.40928939e-01]\n",
            " [ 1.54897389e-01 -2.23758776e-01]\n",
            " [-1.38035949e-01  1.78181233e-01]\n",
            " [-2.33594005e-01  1.30771621e-01]\n",
            " [-3.61730047e-01  4.33121987e-02]] [0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 1 0 1 0 1 1 0\n",
            " 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1\n",
            " 1 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1\n",
            " 1 1 0 0 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1\n",
            " 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 0\n",
            " 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0\n",
            " 0 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0\n",
            " 0 1 1 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 0 0 1 0 0 0\n",
            " 0 0 0 1 0 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0\n",
            " 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0\n",
            " 0 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scatter_plot():\n",
        "  plt.scatter(x[y==0,0], x[y==0,1])\n",
        "  plt.scatter(x[y==1,0], x[y==1,1])"
      ],
      "metadata": {
        "id": "T8iVwiANV1hA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scatter_plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "YJSVdnitywah",
        "outputId": "c34724d2-57b7-44b1-c893-5cb0723c3b4f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, input, h1, output):\n",
        "    super().__init__()\n",
        "    self.linear1= nn.Linear(input,h1)\n",
        "    self.linear2= nn.Linear(h1,output)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = torch.sigmoid(self.linear1(x))\n",
        "    x = torch.sigmoid(self.linear2(x))\n",
        "    return x\n",
        "\n",
        "  def predict(self,x):\n",
        "    pred = self.forward(x)\n",
        "    if pred>=0.5:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0 "
      ],
      "metadata": {
        "id": "YXazilOIyz9f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(2)\n",
        "model = Model(2,4,1)\n",
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2wCe4Db-Yf3",
        "outputId": "616b713f-3fe8-45d1-f293-c3c552b641a1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.1622, -0.1683],\n",
            "        [ 0.1939, -0.0361],\n",
            "        [ 0.3021,  0.1683],\n",
            "        [-0.0813, -0.5717]], requires_grad=True), Parameter containing:\n",
            "tensor([ 0.1614, -0.6260,  0.0929,  0.0470], requires_grad=True), Parameter containing:\n",
            "tensor([[-0.1099,  0.4088,  0.0334,  0.2073]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2116], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "4urytFtyMzxk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "losses=[]\n",
        "\n",
        "for i in range(epochs):\n",
        "  y_pred= model.forward(x_data)\n",
        "  loss= criterion(y_pred,y_data)\n",
        "  print(i,'epochs','loss',loss)\n",
        "  losses.append(loss.item())\n",
        "  optimizer.zero_grad\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Jx9dlIaPF_D",
        "outputId": "4a297819-a431-4d45-90e4-54382e547fcd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 epochs loss tensor(0.7149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "1 epochs loss tensor(0.7148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "2 epochs loss tensor(0.7148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "3 epochs loss tensor(0.7148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "4 epochs loss tensor(0.7147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "5 epochs loss tensor(0.7147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "6 epochs loss tensor(0.7147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "7 epochs loss tensor(0.7146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "8 epochs loss tensor(0.7146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "9 epochs loss tensor(0.7146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "10 epochs loss tensor(0.7145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "11 epochs loss tensor(0.7145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "12 epochs loss tensor(0.7145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "13 epochs loss tensor(0.7144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "14 epochs loss tensor(0.7144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "15 epochs loss tensor(0.7144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "16 epochs loss tensor(0.7143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "17 epochs loss tensor(0.7143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "18 epochs loss tensor(0.7143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "19 epochs loss tensor(0.7142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "20 epochs loss tensor(0.7142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "21 epochs loss tensor(0.7142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "22 epochs loss tensor(0.7141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "23 epochs loss tensor(0.7141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "24 epochs loss tensor(0.7140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "25 epochs loss tensor(0.7140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "26 epochs loss tensor(0.7140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "27 epochs loss tensor(0.7139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "28 epochs loss tensor(0.7139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "29 epochs loss tensor(0.7139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "30 epochs loss tensor(0.7138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "31 epochs loss tensor(0.7138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "32 epochs loss tensor(0.7137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "33 epochs loss tensor(0.7137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "34 epochs loss tensor(0.7137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "35 epochs loss tensor(0.7136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "36 epochs loss tensor(0.7136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "37 epochs loss tensor(0.7135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "38 epochs loss tensor(0.7135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "39 epochs loss tensor(0.7135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "40 epochs loss tensor(0.7134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "41 epochs loss tensor(0.7134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "42 epochs loss tensor(0.7133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "43 epochs loss tensor(0.7133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "44 epochs loss tensor(0.7132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "45 epochs loss tensor(0.7132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "46 epochs loss tensor(0.7132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "47 epochs loss tensor(0.7131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "48 epochs loss tensor(0.7131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "49 epochs loss tensor(0.7130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "50 epochs loss tensor(0.7130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "51 epochs loss tensor(0.7129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "52 epochs loss tensor(0.7129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "53 epochs loss tensor(0.7129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "54 epochs loss tensor(0.7128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "55 epochs loss tensor(0.7128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "56 epochs loss tensor(0.7127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "57 epochs loss tensor(0.7127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "58 epochs loss tensor(0.7126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "59 epochs loss tensor(0.7126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "60 epochs loss tensor(0.7126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "61 epochs loss tensor(0.7125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "62 epochs loss tensor(0.7125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "63 epochs loss tensor(0.7124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "64 epochs loss tensor(0.7124, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "65 epochs loss tensor(0.7123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "66 epochs loss tensor(0.7123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "67 epochs loss tensor(0.7122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "68 epochs loss tensor(0.7122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "69 epochs loss tensor(0.7122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "70 epochs loss tensor(0.7121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "71 epochs loss tensor(0.7121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "72 epochs loss tensor(0.7120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "73 epochs loss tensor(0.7120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "74 epochs loss tensor(0.7119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "75 epochs loss tensor(0.7119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "76 epochs loss tensor(0.7119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "77 epochs loss tensor(0.7118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "78 epochs loss tensor(0.7118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "79 epochs loss tensor(0.7117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "80 epochs loss tensor(0.7117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "81 epochs loss tensor(0.7116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "82 epochs loss tensor(0.7116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "83 epochs loss tensor(0.7115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "84 epochs loss tensor(0.7115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "85 epochs loss tensor(0.7115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "86 epochs loss tensor(0.7114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "87 epochs loss tensor(0.7114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "88 epochs loss tensor(0.7113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "89 epochs loss tensor(0.7113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "90 epochs loss tensor(0.7112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "91 epochs loss tensor(0.7112, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "92 epochs loss tensor(0.7111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "93 epochs loss tensor(0.7111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "94 epochs loss tensor(0.7111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "95 epochs loss tensor(0.7110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "96 epochs loss tensor(0.7110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "97 epochs loss tensor(0.7109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "98 epochs loss tensor(0.7109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "99 epochs loss tensor(0.7108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "100 epochs loss tensor(0.7108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "101 epochs loss tensor(0.7107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "102 epochs loss tensor(0.7107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "103 epochs loss tensor(0.7107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "104 epochs loss tensor(0.7106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "105 epochs loss tensor(0.7106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "106 epochs loss tensor(0.7105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "107 epochs loss tensor(0.7105, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "108 epochs loss tensor(0.7104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "109 epochs loss tensor(0.7104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "110 epochs loss tensor(0.7103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "111 epochs loss tensor(0.7103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "112 epochs loss tensor(0.7103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "113 epochs loss tensor(0.7102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "114 epochs loss tensor(0.7102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "115 epochs loss tensor(0.7101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "116 epochs loss tensor(0.7101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "117 epochs loss tensor(0.7100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "118 epochs loss tensor(0.7100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "119 epochs loss tensor(0.7100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "120 epochs loss tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "121 epochs loss tensor(0.7099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "122 epochs loss tensor(0.7098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "123 epochs loss tensor(0.7098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "124 epochs loss tensor(0.7097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "125 epochs loss tensor(0.7097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "126 epochs loss tensor(0.7097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "127 epochs loss tensor(0.7096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "128 epochs loss tensor(0.7096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "129 epochs loss tensor(0.7095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "130 epochs loss tensor(0.7095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "131 epochs loss tensor(0.7094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "132 epochs loss tensor(0.7094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "133 epochs loss tensor(0.7093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "134 epochs loss tensor(0.7093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "135 epochs loss tensor(0.7093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "136 epochs loss tensor(0.7092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "137 epochs loss tensor(0.7092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "138 epochs loss tensor(0.7091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "139 epochs loss tensor(0.7091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "140 epochs loss tensor(0.7090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "141 epochs loss tensor(0.7090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "142 epochs loss tensor(0.7090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "143 epochs loss tensor(0.7089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "144 epochs loss tensor(0.7089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "145 epochs loss tensor(0.7088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "146 epochs loss tensor(0.7088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "147 epochs loss tensor(0.7088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "148 epochs loss tensor(0.7087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "149 epochs loss tensor(0.7087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "150 epochs loss tensor(0.7086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "151 epochs loss tensor(0.7086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "152 epochs loss tensor(0.7085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "153 epochs loss tensor(0.7085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "154 epochs loss tensor(0.7085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "155 epochs loss tensor(0.7084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "156 epochs loss tensor(0.7084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "157 epochs loss tensor(0.7083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "158 epochs loss tensor(0.7083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "159 epochs loss tensor(0.7082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "160 epochs loss tensor(0.7082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "161 epochs loss tensor(0.7082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "162 epochs loss tensor(0.7081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "163 epochs loss tensor(0.7081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "164 epochs loss tensor(0.7080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "165 epochs loss tensor(0.7080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "166 epochs loss tensor(0.7080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "167 epochs loss tensor(0.7079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "168 epochs loss tensor(0.7079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "169 epochs loss tensor(0.7078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "170 epochs loss tensor(0.7078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "171 epochs loss tensor(0.7078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "172 epochs loss tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "173 epochs loss tensor(0.7077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "174 epochs loss tensor(0.7076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "175 epochs loss tensor(0.7076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "176 epochs loss tensor(0.7075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "177 epochs loss tensor(0.7075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "178 epochs loss tensor(0.7075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "179 epochs loss tensor(0.7074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "180 epochs loss tensor(0.7074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "181 epochs loss tensor(0.7073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "182 epochs loss tensor(0.7073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "183 epochs loss tensor(0.7073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "184 epochs loss tensor(0.7072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "185 epochs loss tensor(0.7072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "186 epochs loss tensor(0.7071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "187 epochs loss tensor(0.7071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "188 epochs loss tensor(0.7071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "189 epochs loss tensor(0.7070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "190 epochs loss tensor(0.7070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "191 epochs loss tensor(0.7069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "192 epochs loss tensor(0.7069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "193 epochs loss tensor(0.7069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "194 epochs loss tensor(0.7068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "195 epochs loss tensor(0.7068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "196 epochs loss tensor(0.7067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "197 epochs loss tensor(0.7067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "198 epochs loss tensor(0.7067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "199 epochs loss tensor(0.7066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "200 epochs loss tensor(0.7066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "201 epochs loss tensor(0.7065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "202 epochs loss tensor(0.7065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "203 epochs loss tensor(0.7065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "204 epochs loss tensor(0.7064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "205 epochs loss tensor(0.7064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "206 epochs loss tensor(0.7064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "207 epochs loss tensor(0.7063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "208 epochs loss tensor(0.7063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "209 epochs loss tensor(0.7062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "210 epochs loss tensor(0.7062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "211 epochs loss tensor(0.7062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "212 epochs loss tensor(0.7061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "213 epochs loss tensor(0.7061, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "214 epochs loss tensor(0.7060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "215 epochs loss tensor(0.7060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "216 epochs loss tensor(0.7060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "217 epochs loss tensor(0.7059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "218 epochs loss tensor(0.7059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "219 epochs loss tensor(0.7058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "220 epochs loss tensor(0.7058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "221 epochs loss tensor(0.7058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "222 epochs loss tensor(0.7057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "223 epochs loss tensor(0.7057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "224 epochs loss tensor(0.7057, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "225 epochs loss tensor(0.7056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "226 epochs loss tensor(0.7056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "227 epochs loss tensor(0.7055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "228 epochs loss tensor(0.7055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "229 epochs loss tensor(0.7055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "230 epochs loss tensor(0.7054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "231 epochs loss tensor(0.7054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "232 epochs loss tensor(0.7054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "233 epochs loss tensor(0.7053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "234 epochs loss tensor(0.7053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "235 epochs loss tensor(0.7052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "236 epochs loss tensor(0.7052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "237 epochs loss tensor(0.7052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "238 epochs loss tensor(0.7051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "239 epochs loss tensor(0.7051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "240 epochs loss tensor(0.7051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "241 epochs loss tensor(0.7050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "242 epochs loss tensor(0.7050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "243 epochs loss tensor(0.7050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "244 epochs loss tensor(0.7049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "245 epochs loss tensor(0.7049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "246 epochs loss tensor(0.7048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "247 epochs loss tensor(0.7048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "248 epochs loss tensor(0.7048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "249 epochs loss tensor(0.7047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "250 epochs loss tensor(0.7047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "251 epochs loss tensor(0.7047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "252 epochs loss tensor(0.7046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "253 epochs loss tensor(0.7046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "254 epochs loss tensor(0.7046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "255 epochs loss tensor(0.7045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "256 epochs loss tensor(0.7045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "257 epochs loss tensor(0.7044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "258 epochs loss tensor(0.7044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "259 epochs loss tensor(0.7044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "260 epochs loss tensor(0.7043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "261 epochs loss tensor(0.7043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "262 epochs loss tensor(0.7043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "263 epochs loss tensor(0.7042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "264 epochs loss tensor(0.7042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "265 epochs loss tensor(0.7042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "266 epochs loss tensor(0.7041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "267 epochs loss tensor(0.7041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "268 epochs loss tensor(0.7041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "269 epochs loss tensor(0.7040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "270 epochs loss tensor(0.7040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "271 epochs loss tensor(0.7039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "272 epochs loss tensor(0.7039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "273 epochs loss tensor(0.7039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "274 epochs loss tensor(0.7038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "275 epochs loss tensor(0.7038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "276 epochs loss tensor(0.7038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "277 epochs loss tensor(0.7037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "278 epochs loss tensor(0.7037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "279 epochs loss tensor(0.7037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "280 epochs loss tensor(0.7036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "281 epochs loss tensor(0.7036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "282 epochs loss tensor(0.7036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "283 epochs loss tensor(0.7035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "284 epochs loss tensor(0.7035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "285 epochs loss tensor(0.7035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "286 epochs loss tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "287 epochs loss tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "288 epochs loss tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "289 epochs loss tensor(0.7033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "290 epochs loss tensor(0.7033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "291 epochs loss tensor(0.7033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "292 epochs loss tensor(0.7032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "293 epochs loss tensor(0.7032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "294 epochs loss tensor(0.7032, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "295 epochs loss tensor(0.7031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "296 epochs loss tensor(0.7031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "297 epochs loss tensor(0.7031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "298 epochs loss tensor(0.7030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "299 epochs loss tensor(0.7030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "300 epochs loss tensor(0.7030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "301 epochs loss tensor(0.7029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "302 epochs loss tensor(0.7029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "303 epochs loss tensor(0.7029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "304 epochs loss tensor(0.7028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "305 epochs loss tensor(0.7028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "306 epochs loss tensor(0.7028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "307 epochs loss tensor(0.7027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "308 epochs loss tensor(0.7027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "309 epochs loss tensor(0.7027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "310 epochs loss tensor(0.7026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "311 epochs loss tensor(0.7026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "312 epochs loss tensor(0.7026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "313 epochs loss tensor(0.7025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "314 epochs loss tensor(0.7025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "315 epochs loss tensor(0.7025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "316 epochs loss tensor(0.7024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "317 epochs loss tensor(0.7024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "318 epochs loss tensor(0.7024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "319 epochs loss tensor(0.7023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "320 epochs loss tensor(0.7023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "321 epochs loss tensor(0.7023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "322 epochs loss tensor(0.7022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "323 epochs loss tensor(0.7022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "324 epochs loss tensor(0.7022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "325 epochs loss tensor(0.7022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "326 epochs loss tensor(0.7021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "327 epochs loss tensor(0.7021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "328 epochs loss tensor(0.7021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "329 epochs loss tensor(0.7020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "330 epochs loss tensor(0.7020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "331 epochs loss tensor(0.7020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "332 epochs loss tensor(0.7019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "333 epochs loss tensor(0.7019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "334 epochs loss tensor(0.7019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "335 epochs loss tensor(0.7018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "336 epochs loss tensor(0.7018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "337 epochs loss tensor(0.7018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "338 epochs loss tensor(0.7017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "339 epochs loss tensor(0.7017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "340 epochs loss tensor(0.7017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "341 epochs loss tensor(0.7017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "342 epochs loss tensor(0.7016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "343 epochs loss tensor(0.7016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "344 epochs loss tensor(0.7016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "345 epochs loss tensor(0.7015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "346 epochs loss tensor(0.7015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "347 epochs loss tensor(0.7015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "348 epochs loss tensor(0.7014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "349 epochs loss tensor(0.7014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "350 epochs loss tensor(0.7014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "351 epochs loss tensor(0.7014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "352 epochs loss tensor(0.7013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "353 epochs loss tensor(0.7013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "354 epochs loss tensor(0.7013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "355 epochs loss tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "356 epochs loss tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "357 epochs loss tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "358 epochs loss tensor(0.7011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "359 epochs loss tensor(0.7011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "360 epochs loss tensor(0.7011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "361 epochs loss tensor(0.7011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "362 epochs loss tensor(0.7010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "363 epochs loss tensor(0.7010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "364 epochs loss tensor(0.7010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "365 epochs loss tensor(0.7009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "366 epochs loss tensor(0.7009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "367 epochs loss tensor(0.7009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "368 epochs loss tensor(0.7009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "369 epochs loss tensor(0.7008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "370 epochs loss tensor(0.7008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "371 epochs loss tensor(0.7008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "372 epochs loss tensor(0.7007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "373 epochs loss tensor(0.7007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "374 epochs loss tensor(0.7007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "375 epochs loss tensor(0.7007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "376 epochs loss tensor(0.7006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "377 epochs loss tensor(0.7006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "378 epochs loss tensor(0.7006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "379 epochs loss tensor(0.7005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "380 epochs loss tensor(0.7005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "381 epochs loss tensor(0.7005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "382 epochs loss tensor(0.7005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "383 epochs loss tensor(0.7004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "384 epochs loss tensor(0.7004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "385 epochs loss tensor(0.7004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "386 epochs loss tensor(0.7003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "387 epochs loss tensor(0.7003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "388 epochs loss tensor(0.7003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "389 epochs loss tensor(0.7003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "390 epochs loss tensor(0.7002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "391 epochs loss tensor(0.7002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "392 epochs loss tensor(0.7002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "393 epochs loss tensor(0.7001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "394 epochs loss tensor(0.7001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "395 epochs loss tensor(0.7001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "396 epochs loss tensor(0.7001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "397 epochs loss tensor(0.7000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "398 epochs loss tensor(0.7000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "399 epochs loss tensor(0.7000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "400 epochs loss tensor(0.7000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "401 epochs loss tensor(0.6999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "402 epochs loss tensor(0.6999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "403 epochs loss tensor(0.6999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "404 epochs loss tensor(0.6999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "405 epochs loss tensor(0.6998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "406 epochs loss tensor(0.6998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "407 epochs loss tensor(0.6998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "408 epochs loss tensor(0.6997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "409 epochs loss tensor(0.6997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "410 epochs loss tensor(0.6997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "411 epochs loss tensor(0.6997, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "412 epochs loss tensor(0.6996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "413 epochs loss tensor(0.6996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "414 epochs loss tensor(0.6996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "415 epochs loss tensor(0.6996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "416 epochs loss tensor(0.6995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "417 epochs loss tensor(0.6995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "418 epochs loss tensor(0.6995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "419 epochs loss tensor(0.6995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "420 epochs loss tensor(0.6994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "421 epochs loss tensor(0.6994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "422 epochs loss tensor(0.6994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "423 epochs loss tensor(0.6994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "424 epochs loss tensor(0.6993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "425 epochs loss tensor(0.6993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "426 epochs loss tensor(0.6993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "427 epochs loss tensor(0.6993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "428 epochs loss tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "429 epochs loss tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "430 epochs loss tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "431 epochs loss tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "432 epochs loss tensor(0.6991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "433 epochs loss tensor(0.6991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "434 epochs loss tensor(0.6991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "435 epochs loss tensor(0.6991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "436 epochs loss tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "437 epochs loss tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "438 epochs loss tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "439 epochs loss tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "440 epochs loss tensor(0.6989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "441 epochs loss tensor(0.6989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "442 epochs loss tensor(0.6989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "443 epochs loss tensor(0.6989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "444 epochs loss tensor(0.6988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "445 epochs loss tensor(0.6988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "446 epochs loss tensor(0.6988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "447 epochs loss tensor(0.6988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "448 epochs loss tensor(0.6987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "449 epochs loss tensor(0.6987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "450 epochs loss tensor(0.6987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "451 epochs loss tensor(0.6987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "452 epochs loss tensor(0.6986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "453 epochs loss tensor(0.6986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "454 epochs loss tensor(0.6986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "455 epochs loss tensor(0.6986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "456 epochs loss tensor(0.6985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "457 epochs loss tensor(0.6985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "458 epochs loss tensor(0.6985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "459 epochs loss tensor(0.6985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "460 epochs loss tensor(0.6984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "461 epochs loss tensor(0.6984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "462 epochs loss tensor(0.6984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "463 epochs loss tensor(0.6984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "464 epochs loss tensor(0.6984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "465 epochs loss tensor(0.6983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "466 epochs loss tensor(0.6983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "467 epochs loss tensor(0.6983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "468 epochs loss tensor(0.6983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "469 epochs loss tensor(0.6982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "470 epochs loss tensor(0.6982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "471 epochs loss tensor(0.6982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "472 epochs loss tensor(0.6982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "473 epochs loss tensor(0.6982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "474 epochs loss tensor(0.6981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "475 epochs loss tensor(0.6981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "476 epochs loss tensor(0.6981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "477 epochs loss tensor(0.6981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "478 epochs loss tensor(0.6980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "479 epochs loss tensor(0.6980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "480 epochs loss tensor(0.6980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "481 epochs loss tensor(0.6980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "482 epochs loss tensor(0.6979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "483 epochs loss tensor(0.6979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "484 epochs loss tensor(0.6979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "485 epochs loss tensor(0.6979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "486 epochs loss tensor(0.6979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "487 epochs loss tensor(0.6978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "488 epochs loss tensor(0.6978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "489 epochs loss tensor(0.6978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "490 epochs loss tensor(0.6978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "491 epochs loss tensor(0.6978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "492 epochs loss tensor(0.6977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "493 epochs loss tensor(0.6977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "494 epochs loss tensor(0.6977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "495 epochs loss tensor(0.6977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "496 epochs loss tensor(0.6976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "497 epochs loss tensor(0.6976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "498 epochs loss tensor(0.6976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "499 epochs loss tensor(0.6976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "500 epochs loss tensor(0.6976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "501 epochs loss tensor(0.6975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "502 epochs loss tensor(0.6975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "503 epochs loss tensor(0.6975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "504 epochs loss tensor(0.6975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "505 epochs loss tensor(0.6975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "506 epochs loss tensor(0.6974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "507 epochs loss tensor(0.6974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "508 epochs loss tensor(0.6974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "509 epochs loss tensor(0.6974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "510 epochs loss tensor(0.6974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "511 epochs loss tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "512 epochs loss tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "513 epochs loss tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "514 epochs loss tensor(0.6973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "515 epochs loss tensor(0.6972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "516 epochs loss tensor(0.6972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "517 epochs loss tensor(0.6972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "518 epochs loss tensor(0.6972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "519 epochs loss tensor(0.6972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "520 epochs loss tensor(0.6971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "521 epochs loss tensor(0.6971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "522 epochs loss tensor(0.6971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "523 epochs loss tensor(0.6971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "524 epochs loss tensor(0.6971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "525 epochs loss tensor(0.6970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "526 epochs loss tensor(0.6970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "527 epochs loss tensor(0.6970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "528 epochs loss tensor(0.6970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "529 epochs loss tensor(0.6970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "530 epochs loss tensor(0.6970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "531 epochs loss tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "532 epochs loss tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "533 epochs loss tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "534 epochs loss tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "535 epochs loss tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "536 epochs loss tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "537 epochs loss tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "538 epochs loss tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "539 epochs loss tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "540 epochs loss tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "541 epochs loss tensor(0.6967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "542 epochs loss tensor(0.6967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "543 epochs loss tensor(0.6967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "544 epochs loss tensor(0.6967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "545 epochs loss tensor(0.6967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "546 epochs loss tensor(0.6966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "547 epochs loss tensor(0.6966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "548 epochs loss tensor(0.6966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "549 epochs loss tensor(0.6966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "550 epochs loss tensor(0.6966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "551 epochs loss tensor(0.6966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "552 epochs loss tensor(0.6965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "553 epochs loss tensor(0.6965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "554 epochs loss tensor(0.6965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "555 epochs loss tensor(0.6965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "556 epochs loss tensor(0.6965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "557 epochs loss tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "558 epochs loss tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "559 epochs loss tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "560 epochs loss tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "561 epochs loss tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "562 epochs loss tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "563 epochs loss tensor(0.6963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "564 epochs loss tensor(0.6963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "565 epochs loss tensor(0.6963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "566 epochs loss tensor(0.6963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "567 epochs loss tensor(0.6963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "568 epochs loss tensor(0.6963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "569 epochs loss tensor(0.6962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "570 epochs loss tensor(0.6962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "571 epochs loss tensor(0.6962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "572 epochs loss tensor(0.6962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "573 epochs loss tensor(0.6962, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "574 epochs loss tensor(0.6961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "575 epochs loss tensor(0.6961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "576 epochs loss tensor(0.6961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "577 epochs loss tensor(0.6961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "578 epochs loss tensor(0.6961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "579 epochs loss tensor(0.6961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "580 epochs loss tensor(0.6960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "581 epochs loss tensor(0.6960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "582 epochs loss tensor(0.6960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "583 epochs loss tensor(0.6960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "584 epochs loss tensor(0.6960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "585 epochs loss tensor(0.6960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "586 epochs loss tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "587 epochs loss tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "588 epochs loss tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "589 epochs loss tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "590 epochs loss tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "591 epochs loss tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "592 epochs loss tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "593 epochs loss tensor(0.6958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "594 epochs loss tensor(0.6958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "595 epochs loss tensor(0.6958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "596 epochs loss tensor(0.6958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "597 epochs loss tensor(0.6958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "598 epochs loss tensor(0.6958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "599 epochs loss tensor(0.6957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "600 epochs loss tensor(0.6957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "601 epochs loss tensor(0.6957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "602 epochs loss tensor(0.6957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "603 epochs loss tensor(0.6957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "604 epochs loss tensor(0.6957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "605 epochs loss tensor(0.6956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "606 epochs loss tensor(0.6956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "607 epochs loss tensor(0.6956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "608 epochs loss tensor(0.6956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "609 epochs loss tensor(0.6956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "610 epochs loss tensor(0.6956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "611 epochs loss tensor(0.6956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "612 epochs loss tensor(0.6955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "613 epochs loss tensor(0.6955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "614 epochs loss tensor(0.6955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "615 epochs loss tensor(0.6955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "616 epochs loss tensor(0.6955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "617 epochs loss tensor(0.6955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "618 epochs loss tensor(0.6954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "619 epochs loss tensor(0.6954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "620 epochs loss tensor(0.6954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "621 epochs loss tensor(0.6954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "622 epochs loss tensor(0.6954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "623 epochs loss tensor(0.6954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "624 epochs loss tensor(0.6954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "625 epochs loss tensor(0.6953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "626 epochs loss tensor(0.6953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "627 epochs loss tensor(0.6953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "628 epochs loss tensor(0.6953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "629 epochs loss tensor(0.6953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "630 epochs loss tensor(0.6953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "631 epochs loss tensor(0.6953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "632 epochs loss tensor(0.6952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "633 epochs loss tensor(0.6952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "634 epochs loss tensor(0.6952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "635 epochs loss tensor(0.6952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "636 epochs loss tensor(0.6952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "637 epochs loss tensor(0.6952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "638 epochs loss tensor(0.6952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "639 epochs loss tensor(0.6952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "640 epochs loss tensor(0.6951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "641 epochs loss tensor(0.6951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "642 epochs loss tensor(0.6951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "643 epochs loss tensor(0.6951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "644 epochs loss tensor(0.6951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "645 epochs loss tensor(0.6951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "646 epochs loss tensor(0.6951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "647 epochs loss tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "648 epochs loss tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "649 epochs loss tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "650 epochs loss tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "651 epochs loss tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "652 epochs loss tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "653 epochs loss tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "654 epochs loss tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "655 epochs loss tensor(0.6949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "656 epochs loss tensor(0.6949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "657 epochs loss tensor(0.6949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "658 epochs loss tensor(0.6949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "659 epochs loss tensor(0.6949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "660 epochs loss tensor(0.6949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "661 epochs loss tensor(0.6949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "662 epochs loss tensor(0.6948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "663 epochs loss tensor(0.6948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "664 epochs loss tensor(0.6948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "665 epochs loss tensor(0.6948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "666 epochs loss tensor(0.6948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "667 epochs loss tensor(0.6948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "668 epochs loss tensor(0.6948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "669 epochs loss tensor(0.6948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "670 epochs loss tensor(0.6948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "671 epochs loss tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "672 epochs loss tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "673 epochs loss tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "674 epochs loss tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "675 epochs loss tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "676 epochs loss tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "677 epochs loss tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "678 epochs loss tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "679 epochs loss tensor(0.6946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "680 epochs loss tensor(0.6946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "681 epochs loss tensor(0.6946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "682 epochs loss tensor(0.6946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "683 epochs loss tensor(0.6946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "684 epochs loss tensor(0.6946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "685 epochs loss tensor(0.6946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "686 epochs loss tensor(0.6946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "687 epochs loss tensor(0.6946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "688 epochs loss tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "689 epochs loss tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "690 epochs loss tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "691 epochs loss tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "692 epochs loss tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "693 epochs loss tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "694 epochs loss tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "695 epochs loss tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "696 epochs loss tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "697 epochs loss tensor(0.6944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "698 epochs loss tensor(0.6944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "699 epochs loss tensor(0.6944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "700 epochs loss tensor(0.6944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "701 epochs loss tensor(0.6944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "702 epochs loss tensor(0.6944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "703 epochs loss tensor(0.6944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "704 epochs loss tensor(0.6944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "705 epochs loss tensor(0.6944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "706 epochs loss tensor(0.6943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "707 epochs loss tensor(0.6943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "708 epochs loss tensor(0.6943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "709 epochs loss tensor(0.6943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "710 epochs loss tensor(0.6943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "711 epochs loss tensor(0.6943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "712 epochs loss tensor(0.6943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "713 epochs loss tensor(0.6943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "714 epochs loss tensor(0.6943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "715 epochs loss tensor(0.6943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "716 epochs loss tensor(0.6942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "717 epochs loss tensor(0.6942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "718 epochs loss tensor(0.6942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "719 epochs loss tensor(0.6942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "720 epochs loss tensor(0.6942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "721 epochs loss tensor(0.6942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "722 epochs loss tensor(0.6942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "723 epochs loss tensor(0.6942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "724 epochs loss tensor(0.6942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "725 epochs loss tensor(0.6942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "726 epochs loss tensor(0.6941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "727 epochs loss tensor(0.6941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "728 epochs loss tensor(0.6941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "729 epochs loss tensor(0.6941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "730 epochs loss tensor(0.6941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "731 epochs loss tensor(0.6941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "732 epochs loss tensor(0.6941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "733 epochs loss tensor(0.6941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "734 epochs loss tensor(0.6941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "735 epochs loss tensor(0.6941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "736 epochs loss tensor(0.6941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "737 epochs loss tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "738 epochs loss tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "739 epochs loss tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "740 epochs loss tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "741 epochs loss tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "742 epochs loss tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "743 epochs loss tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "744 epochs loss tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "745 epochs loss tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "746 epochs loss tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "747 epochs loss tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "748 epochs loss tensor(0.6939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "749 epochs loss tensor(0.6939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "750 epochs loss tensor(0.6939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "751 epochs loss tensor(0.6939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "752 epochs loss tensor(0.6939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "753 epochs loss tensor(0.6939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "754 epochs loss tensor(0.6939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "755 epochs loss tensor(0.6939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "756 epochs loss tensor(0.6939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "757 epochs loss tensor(0.6939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "758 epochs loss tensor(0.6939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "759 epochs loss tensor(0.6939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "760 epochs loss tensor(0.6939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "761 epochs loss tensor(0.6938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "762 epochs loss tensor(0.6938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "763 epochs loss tensor(0.6938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "764 epochs loss tensor(0.6938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "765 epochs loss tensor(0.6938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "766 epochs loss tensor(0.6938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "767 epochs loss tensor(0.6938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "768 epochs loss tensor(0.6938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "769 epochs loss tensor(0.6938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "770 epochs loss tensor(0.6938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "771 epochs loss tensor(0.6938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "772 epochs loss tensor(0.6938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "773 epochs loss tensor(0.6938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "774 epochs loss tensor(0.6937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "775 epochs loss tensor(0.6937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "776 epochs loss tensor(0.6937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "777 epochs loss tensor(0.6937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "778 epochs loss tensor(0.6937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "779 epochs loss tensor(0.6937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "780 epochs loss tensor(0.6937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "781 epochs loss tensor(0.6937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "782 epochs loss tensor(0.6937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "783 epochs loss tensor(0.6937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "784 epochs loss tensor(0.6937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "785 epochs loss tensor(0.6937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "786 epochs loss tensor(0.6937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "787 epochs loss tensor(0.6937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "788 epochs loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "789 epochs loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "790 epochs loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "791 epochs loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "792 epochs loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "793 epochs loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "794 epochs loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "795 epochs loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "796 epochs loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "797 epochs loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "798 epochs loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "799 epochs loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "800 epochs loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "801 epochs loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "802 epochs loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "803 epochs loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "804 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "805 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "806 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "807 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "808 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "809 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "810 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "811 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "812 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "813 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "814 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "815 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "816 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "817 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "818 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "819 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "820 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "821 epochs loss tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "822 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "823 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "824 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "825 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "826 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "827 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "828 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "829 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "830 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "831 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "832 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "833 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "834 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "835 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "836 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "837 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "838 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "839 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "840 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "841 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "842 epochs loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "843 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "844 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "845 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "846 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "847 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "848 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "849 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "850 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "851 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "852 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "853 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "854 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "855 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "856 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "857 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "858 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "859 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "860 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "861 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "862 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "863 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "864 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "865 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "866 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "867 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "868 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "869 epochs loss tensor(0.6933, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "870 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "871 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "872 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "873 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "874 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "875 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "876 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "877 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "878 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "879 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "880 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "881 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "882 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "883 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "884 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "885 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "886 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "887 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "888 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "889 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "890 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "891 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "892 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "893 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "894 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "895 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "896 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "897 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "898 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "899 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "900 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "901 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "902 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "903 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "904 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "905 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "906 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "907 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "908 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "909 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "910 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "911 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "912 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "913 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "914 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "915 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "916 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "917 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "918 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "919 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "920 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "921 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "922 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "923 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "924 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "925 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "926 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "927 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "928 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "929 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "930 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "931 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "932 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "933 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "934 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "935 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "936 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "937 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "938 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "939 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "940 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "941 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "942 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "943 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "944 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "945 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "946 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "947 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "948 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "949 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "950 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "951 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "952 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "953 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "954 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "955 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "956 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "957 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "958 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "959 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "960 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "961 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "962 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "963 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "964 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "965 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "966 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "967 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "968 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "969 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "970 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "971 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "972 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "973 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "974 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "975 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "976 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "977 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "978 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "979 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "980 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "981 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "982 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "983 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "984 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "985 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "986 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "987 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "988 epochs loss tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "989 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "990 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "991 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "992 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "993 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "994 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "995 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "996 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "997 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "998 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "999 epochs loss tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(epochs), losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "2qjPD4n9QsiD",
        "outputId": "83242221-a5b2-4e90-d392-7b1400a4aed8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2289a9ce90>]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}